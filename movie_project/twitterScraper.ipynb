{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from time import sleep\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import math\n",
    "import glob\n",
    "from tweepy import TweepError\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# edit these three variables\n",
    "user = 'potus'\n",
    "\n",
    "# only edit these if you're having problems\n",
    "delay = 1  # time to wait on each page load before reading the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #raise IOError(\"Forcing\")\n",
    "    with open(user+'.pickle', 'rb') as handle:\n",
    "        tweetCutoff = pickle.load(handle)\n",
    "except IOError:\n",
    "    if user == 'vp':\n",
    "        tweetCutoff = 927930606222274560\n",
    "    elif user == 'realdonaldtrump':\n",
    "        tweetCutoff = 927673257230327808\n",
    "    elif user == 'potus':\n",
    "        tweetCutoff = 928056523766497280\n",
    "    else:\n",
    "        raise ValueError(\"Not implemented yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_selector = 'li.js-stream-item'\n",
    "user = user.lower()\n",
    "ids = []\n",
    "id_selector = '.time a.tweet-timestamp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = {'consumer_key' : 'znPXxNt7LcofyAYpuMOdfO23Q',\n",
    "        'consumer_secret' : 'MGrKG8lv6r20Sa47gbheDWs3jhJXWVMkMp3VJxxRP74LQd5U6D',\n",
    "        'access_token' : '935858594431553538-UidHBRgEZC2Q7hhEcbbE1HaSKrzy8JR',\n",
    "        'access_token_secret' : 'P3mNnM67hWzFBg9uAJJRkv7PWSscx2NsPkJUJU04HaHsa'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()  # options are Chrome() Firefox() Safari()\n",
    "driver.get('https://twitter.com/'+user)\n",
    "quit = False\n",
    "n = 0\n",
    "ids = []\n",
    "while not quit:\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    sleep(2)\n",
    "    found_tweets = driver.find_elements_by_css_selector(tweet_selector)\n",
    "    for tweet in found_tweets[n:]:\n",
    "        if tweet.find_element_by_css_selector('div.tweet').get_attribute('data-retweet-id'):\n",
    "            ids_ = tweet.find_element_by_css_selector('div.tweet').get_attribute('data-retweet-id')\n",
    "            ids.append(ids_)\n",
    "        else:\n",
    "            ids_ = tweet.find_element_by_css_selector('div.tweet').get_attribute('data-tweet-id')\n",
    "            ids.append(ids_)\n",
    "        if int(ids_) == int(tweetCutoff):\n",
    "            quit = True\n",
    "            break\n",
    "            \n",
    "    n = len(found_tweets)\n",
    "    \n",
    "    \n",
    "    \n",
    "if found_tweets[0].find_element_by_css_selector('div.tweet').get_attribute('data-retweet-id'):\n",
    "    tweetCutoff = found_tweets[0].find_element_by_css_selector('div.tweet').get_attribute('data-retweet-id')\n",
    "else:\n",
    "    tweetCutoff = found_tweets[0].find_element_by_css_selector('div.tweet').get_attribute('data-tweet-id')    \n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total ids: 4\n"
     ]
    }
   ],
   "source": [
    "consumer_key = keys['consumer_key']\n",
    "consumer_secret = keys['consumer_secret']\n",
    "access_token = keys['access_token']\n",
    "access_token_secret = keys['access_token_secret']\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "print('total ids: {}'.format(len(ids)))\n",
    "\n",
    "all_data = []\n",
    "start = 0\n",
    "end = 100\n",
    "limit = len(ids)\n",
    "i = math.ceil(limit / 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isRetweet(entry):\n",
    "    return 'retweeted_status' in entry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently getting 0 - 100\n"
     ]
    }
   ],
   "source": [
    "for go in xrange(int(i)):\n",
    "    print('currently getting {} - {}'.format(start, end))\n",
    "    if go:\n",
    "        sleep(10)  # needed to prevent hitting API rate limit\n",
    "    id_batch = ids[start:end]\n",
    "    start += 100\n",
    "    end += 100\n",
    "    tweets = api.statuses_lookup(id_batch)\n",
    "    for tweet in tweets:\n",
    "        all_data.append(dict(tweet._json))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parsed_data = []\n",
    "for i, d in enumerate(all_data):\n",
    "    text =  d['text'].encode('utf-8').strip()\n",
    "    parsed_data.append((isRetweet(d), d['created_at'],text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_old = pd.read_csv(user+'.csv')\n",
    "except IOError:\n",
    "    df_old = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsed_data, columns = ['is_retweet', 'created_at', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat([df_old, df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(user+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(user+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(tweetCutoff, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
